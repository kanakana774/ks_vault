# チューニング

### PostgreSQL 実行計画によるパフォーマンス改善の実践的な手法

実行計画は、SQL のボトルネックを特定し、効果的なチューニングを行うための羅針盤です。闇雲にインデックスを追加したり、設定値を変更したりする前に、必ず実行計画を確認する習慣をつけましょう。

#### ステップ 1: ボトルネッククエリの特定

まず、システム全体でパフォーマンス上の問題を引き起こしているクエリを特定します。

- **長期実行クエリのモニタリング**: `pg_stat_activity` ビューや、APM (Application Performance Monitoring) ツールを使って、長時間実行されているクエリや頻繁に実行されるクエリを特定します。
- **ログの分析**: PostgreSQL のログ設定で、一定時間以上かかるクエリをログに出力するように設定し（`log_min_duration_statement`）、それを分析します。
- **再現性の確認**: 可能であれば、問題を再現できる最小限のデータセットと環境を用意します。

#### ステップ 2: `EXPLAIN ANALYZE` の取得と基本的な確認 ★

特定したクエリに対して、`EXPLAIN ANALYZE` を実行します。`BUFFERS` オプションも追加すると、ディスク I/O に関する詳細もわかり、さらに分析が深まります。

```sql
EXPLAIN (ANALYZE, VERBOSE, BUFFERS) YOUR_SQL_STATEMENT;
```

**基本的な確認ポイント:**

1.  **`Execution Time`**: クエリ全体の実行時間。これが問題視している時間と一致しているか確認します。
2.  **`Planning Time`**: クエリの実行計画を生成するのにかかった時間。これが異常に長い場合、統計情報が古すぎるか、非常に複雑なクエリである可能性があります。
3.  **一番時間のかかっているノードの特定**: 実行計画の各ノードの `actual time` を見て、最も時間がかかっているノード（ホットスポット）を見つけます。チューニングの優先順位はここに集中します。
4.  **`rows` (推定) vs `actual rows` (実際) の乖離**:
    - この乖離が大きい場合、オプティマイザの統計情報が不正確である可能性が高いです。統計情報が古いと、オプティマイザが間違った実行計画を選択してしまいます。

> ⇒ とはいったものの実際に実務で巨大テーブルを扱う場合、だいたい index なしで検索されてないかチェックすることがほとんどかと思いますので、まずは Seq Scan が発生してる箇所をなんとか index を使ったクエリに変えられないか見ることになると思います。ちなみに、index は勝手に作ったりとかはできないと思うので、どうしてもパフォーマンスが悪い際に index を張るか偉い人と相談みたいな感じになるかと思います。なのでまずはパフォーマンス悪そうだなを見つけられるようになることがここでの目標です。

#### ステップ 3: ボトルネックノードの種類に応じた詳細分析と対策

最も時間のかかっているノードを特定したら、そのノードの種類に応じて具体的な対策を検討します。

##### 3.1. スキャン操作 (`Seq Scan`, `Index Scan`, `Bitmap Heap Scan`) がボトルネックの場合

- **`Seq Scan` がボトルネック (`actual time` が長い) の場合**:
  - **原因**: テーブル全体をスキャンしているため。`WHERE` 句や `JOIN` 句の条件で効率的に行を絞り込めていない。
  - **対策**:
    - **インデックスの追加**: `WHERE` 句や `JOIN` 句で使われているカラムに適切なインデックス（`B-tree` が一般的）を作成します。
      ```sql
      CREATE INDEX idx_table_column ON your_table (column_name);
      ```
    - **複合インデックス**: 複数のカラムで絞り込んでいる場合（例: `WHERE column1 = ? AND column2 = ?`）、複合インデックスを検討します。
      ```sql
      CREATE INDEX idx_table_col1_col2 ON your_table (column1, column2);
      ```
      **注意**: 複合インデックスは、先頭のカラムから順に使われることに注意してください（左端プレフィックス規則）。
    - **`ANALYZE` の実行**: インデックスを作成・削除した場合、必ず `ANALYZE your_table;` を実行して統計情報を更新します。
    - **条件の見直し**: `WHERE` 句の条件がインデックスを使えない形になっていないか確認します（例: `column + 1 = ?`, `LOWER(column) = ?` など。関数を使っているとインデックスが使えないことが多い）。
      - **対策**: 関数インデックス (Function Index) を検討する。
        ```sql
        CREATE INDEX idx_table_lower_column ON your_table (LOWER(column_name));
        ```
- **`Index Scan` や `Bitmap Heap Scan` の `actual time` が長い場合**:
  - **原因**: インデックス自体は使われているが、依然としてコストが高い。
    - **大量の行を取得している**: インデックスで絞り込んでも、結局大量の行が返され、その都度テーブルヒープへのアクセスが発生している。
    - **`Index Only Scan` になっていない**: `SELECT` 句にインデックスに含まれていないカラムがあり、テーブルヒープへのアクセス（visibility map の確認も含む）が発生している。
  - **対策**:
    - **インデックスの改善 (Index Only Scan 狙い)**: `SELECT` 句で取得したいカラムがインデックスに含まれていない場合、`INCLUDE` 句でインデックスに追加することを検討します。これにより、テーブルヒープへのアクセスを減らせる可能性があります（ただし、インデックスサイズが大きくなるトレードオフ）。
      ```sql
      CREATE INDEX idx_table_col1_incl_col2 ON your_table (column1) INCLUDE (column2);
      ```
    - **取得行数の削減**: そもそも、本当にそんなに多くの行が必要なのか？ `LIMIT` 句を追加したり、アプリケーション側で必要なデータのみをフェッチするように見直します。
    - **Partial Index**: 特定の条件に合致するデータが少ない場合、その条件でフィルタリングされた部分的なインデックスを作成することで、インデックスサイズを小さくし、検索効率を高めます。
      ```sql
      CREATE INDEX idx_table_status_active ON your_table (column_name) WHERE status = 'active';
      ```
- **`Buffers` 情報の活用**:
  - `shared hit`: 共有バッファからの読み込みヒット数。これが高いほどメモリ内で処理が完結しており高速です。
  - `shared read`: 共有バッファに存在せず、ディスクから読み込まれた回数。これが高い場合、I/O がボトルネックの可能性があります。`shared_buffers` の設定を見直したり、キャッシュヒット率が低い原因を探ります。
  - `temp read`/`temp write`: 一時ファイルへの読み書き。これが高い場合、メモリが足りずディスクにスピルしていることを意味します。`work_mem` の設定を見直します。

##### 3.2. 結合操作 (`Hash Join`, `Nested Loop Join`, `Merge Join`) がボトルネックの場合

- **`actual time` が長い結合ノードの特定**:
  - **`Hash Join` が遅い場合**:
    - **原因**: ハッシュテーブルの構築に時間がかかっている（`Hash` ノードの `actual time` を確認）。または、ハッシュテーブルがメモリに収まらず、ディスクにスピルしている（`temp write` が多い）。
    - **対策**:
      - **`work_mem` の増強**: `work_mem` の設定値を増やし、ハッシュテーブルがメモリ内に収まるようにします。
      - **結合順序の最適化**: 結合するテーブルの順序をオプティマイザが間違えている可能性。小さいテーブルを先にハッシュビルド側に持ってくるのが理想。
      - **前段のスキャン・フィルタリングの改善**: 結合に渡される行数を減らすことで、ハッシュテーブルのサイズが小さくなり、高速化されます。
  - **`Nested Loop Join` が遅い場合**:
    - **原因**: 外部テーブルの各行に対して、内部テーブルが効率的に検索できていない。内部テーブルに適切なインデックスがない。
    - **対策**:
      - **内部テーブルにインデックス**: 内部テーブル（`loops` 数が多く、かつ `actual time` が長い側のノード）の結合キーにインデックスを作成します。
      - **結合順序の確認**: 外部テーブルの行数が少なく、内部テーブルにインデックスが効くように結合順序になっているか確認します。
      - **前段のスキャン・フィルタリングの改善**: 外部テーブルの行数を減らすことで、内部ループの実行回数が減ります。
  - **`Merge Join` が遅い場合**:
    - **原因**: 結合前にソートが必要な場合、そのソートに時間がかかっている。
    - **対策**:
      - **ソートの回避**: 結合キーにインデックスがあり、それがソート済みデータとして利用できる場合はソートが省略されます。インデックスの追加を検討します。
      - **`work_mem` の増強**: ソートがメモリ内で完結するように `work_mem` を調整します。

##### 3.3. ソート操作 (`Sort`) がボトルネックの場合

- **`actual time` が長い `Sort` ノードの特定**:
  - **原因**: `ORDER BY`, `GROUP BY`, `DISTINCT` などによってソートが必要になっている。ソート対象のデータ量が多すぎる。メモリに収まらずディスクにスピルしている。
  - **対策**:
    - **`work_mem` の増強**: ソートがメモリ内で完結するように `work_mem` の設定値を増やします。`Sort Method: external merge` と表示されている場合、メモリ不足でディスクに書き出しています。
    - **インデックスの利用**: `ORDER BY` 句で使われているカラムにインデックスを作成することで、ソート処理をインデックススキャンで代替できる場合があります。複合インデックスの場合、`ORDER BY` のカラム順がインデックス順と一致している必要があります。
      ```sql
      CREATE INDEX idx_table_col_order ON your_table (column_name DESC);
      ```
    - **ソート対象の削減**: 前段の `WHERE` 句などでデータを絞り込み、ソート対象の行数を減らします。
    - **`LIMIT` の活用**: `LIMIT` 句が使われている場合、`Sort Method: top-N heapsort` となっていれば、PostgreSQL は効率的なアルゴリズムを使用しています。

##### 3.4. 集約操作 (`Aggregate`, `HashAggregate`) がボトルネックの場合

- **`actual time` が長い `Aggregate` ノードの特定**:
  - **原因**: 集約対象のデータ量が多い。`GROUP BY` のキーが多く、ハッシュテーブルの構築に時間がかかっている。
  - **対策**:
    - **前段のフィルタリングの改善**: `WHERE` 句で集約対象の行数を減らします。
    - **`work_mem` の増強**: `HashAggregate` の場合、ハッシュテーブルがメモリ内で完結するように `work_mem` を調整します。
    - **`GROUP BY` キーの見直し**: 必要なキーのみに絞り込むことを検討します。

#### ステップ 4: 統計情報の更新

`rows` と `actual rows` の乖離が大きい場合は、オプティマイザの判断材料となる統計情報が古いため、必ず `ANALYZE` を実行します。テーブルのデータが頻繁に更新される場合は、定期的な `ANALYZE` や `VACUUM ANALYZE` の実行が重要です。

```sql
ANALYZE your_table_name; -- 特定のテーブル
ANALYZE; -- 全データベース
```

#### ステップ 5: 設定パラメータの調整

`postgresql.conf` ファイルで、上記で言及したようなパラメータを調整します。変更後は PostgreSQL の再起動（または `pg_reload_conf()`）が必要です。

- `shared_buffers`: PostgreSQL が共有メモリで使用するバッファサイズ。ディスク I/O が多い場合に検討。
- `work_mem`: ソート、ハッシュ、マージジョインなどの操作でプライベートに使用されるメモリ量。`external merge` や `temp write` が多い場合に検討。
- `maintenance_work_mem`: `VACUUM`, `CREATE INDEX`, `ALTER TABLE` などで使われるメモリ量。インデックス作成が遅い場合に検討。
- `random_page_cost`, `cpu_tuple_cost` など: オプティマイザのコスト計算モデルに影響を与えるパラメータ。通常はデフォルトで問題ないが、特殊な環境（SSD 環境など）では調整を検討。

#### ステップ 6: SQL の書き換え

データベース側のチューニングだけでなく、SQL の書き方自体を見直すことも重要です。

- **`SELECT *` の回避**: 必要なカラムのみを選択します。
- **不必要な `JOIN` の回避**: 不要なテーブルとの結合を削除します。
- **サブクエリの結合への書き換え**: 特に相関サブクエリは、適切にインデックスが効いていないと効率が悪くなりがちです。多くの場合、`JOIN` や `LATERAL JOIN` に書き換えることでパフォーマンスが向上します。
  - **例:** `WHERE EXISTS (SELECT 1 FROM orders o WHERE o.user_id = u.id)` は、`INNER JOIN orders o ON u.id = o.user_id` と `DISTINCT` の組み合わせで書き換えられることが多いです。

#### ステップ 7: 繰り返しと検証

パフォーマンスチューニングは一度で終わるものではありません。

1.  変更を適用する。
2.  再度 `EXPLAIN ANALYZE` を取得し、効果を確認する。
3.  ベンチマークや実際のアプリケーションでパフォーマンス改善が確認できるまで、ステップ 2〜6 を繰り返します。
4.  変更は一度に一つずつ行い、効果を測定することが重要です。


